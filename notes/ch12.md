# Chapter 12: Anti-Entropy and Dissemination

## Data Propagation Approaches

To reliably propagate data records throughout a distributed system, we need the propagating node to be available and able to reach other nodes, though throughput is limited to a single machine. Updates can generally propagate to all nodes in the cluster using one of three broad groups of approaches:

1. **Direct notification**: Broadcast from one process to all others
2. **Periodic peer-to-peer information exchange**
3. **Cooperative broadcast**: Message recipients become broadcasters themselves, helping to spread information quicker and more widely

## Entropy and Anti-Entropy

**Entropy** is a property that represents the measure of disorder in a distributed system. Since this property is undesired and its amount should be kept to a minimum, there are many techniques to deal with it.

**Anti-entropy** is usually used to bring nodes back up to date when the primary delivery mechanism has failed. The system can continue functioning correctly even if the coordinator fails at some point, since other nodes will continue spreading the information. In other words, anti-entropy is used to lower the convergence time bounds in eventually consistent systems.

## Detection and Repair Mechanisms

### Read Repair

It is easiest to detect divergence between replicas during reads, since at that point we can contact replicas and request the current state from each one of them. The coordinator performs a distributed read, optimistically assuming that replicas are in sync and have the same information available. This mechanism is called **read repair** and is often used to detect and eliminate inconsistencies.

Read repair can be implemented as:

- Self-healing operation
- Asynchronous operation

Instead of issuing a full read request to each node, the coordinator can issue only one full read request and send only digest requests to the other replicas.

### Hinted Handoff

Another anti-entropy approach is called **hinted handoff**, a write-side repair mechanism. If the target node fails to acknowledge the write, the coordinator or one of the replicas stores a specific hint that is dispatched to the target node as soon as it comes back.

## Merkle Trees

Finding exactly which rows have diverged between replicas requires exchanging and comparing data records pairwise, which is impractical and expensive. Many databases employ **Merkle trees** to reduce the cost of reconciliation.

Merkle trees compose a compact hashed representation of the local data, building a tree of hashes:

- The lowest level of this hash tree is built by scanning an entire table holding data records
- Higher tree levels contain hashes of the lower-level hashes
- This builds a hash-stable, hierarchical representation that allows us to quickly detect inconsistencies
- We can compare the hashes, following the hash-tree nodes recursively to narrow down inconsistent ranges

## Gossip Protocols

Gossip protocols are probabilistic communication procedures based on how rumors spread in human society and how diseases spread:

- A process that holds a record that needs to be spread is considered "infected"
- Any process that receives this information becomes "susceptible"
- Gossip can be used for asynchronous message delivery in homogeneous decentralized systems
- These protocols are very robust and help to achieve high reliability despite the inherent unreliability of distributed systems

# 第12章: アンチエントロピーと情報伝播

## データ伝播のアプローチ

分散システム全体にデータレコードを確実に伝播させるには、伝播するノードが利用可能で他のノードに到達できる必要がありますが、スループットは単一マシンに制限されます。クラスター内のすべてのノードへの更新は、一般的に以下の3つの大きなアプローチグループのいずれかを使用して伝播します：

1. **直接通知**: 1つのプロセスから他のすべてのプロセスへのブロードキャスト
2. **定期的なピアツーピア情報交換**
3. **協調的ブロードキャスト**: メッセージの受信者自身がブロードキャスターとなり、情報をより迅速に、より広範囲に拡散するのを助ける

## エントロピーとアンチエントロピー

**エントロピー**は分散システムにおける無秩序の度合いを表す特性です。この特性は望ましくなく、その量を最小限に抑える必要があるため、これに対処するための多くの技術があります。

**アンチエントロピー**は通常、主要な配信メカニズムが失敗した場合にノードを最新の状態に戻すために使用されます。コーディネーターが途中で失敗しても、他のノードが情報の拡散を継続するため、システムは正常に機能し続けることができます。言い換えれば、アンチエントロピーは結果整合性システムにおける収束時間の境界を下げるために使用されます。

## 検出と修復のメカニズム

### リードリペア

レプリカ間の不一致を検出するのは読み取り操作中が最も簡単です。その時点でレプリカに接続し、それぞれの現在の状態を要求できるからです。コーディネーターは分散読み取りを実行し、楽観的にレプリカが同期しており同じ情報を持っていると仮定します。このメカニズムは**リードリペア**と呼ばれ、不整合を検出して排除するためによく使用されます。

リードリペアは以下のように実装できます：

- 自己修復操作
- 非同期操作

各ノードにフル読み取りリクエストを発行する代わりに、コーディネーターは1つのノードにのみフル読み取りリクエストを発行し、他のレプリカにはダイジェストリクエストのみを送信することができます。

### ヒンテッドハンドオフ

もう一つのアンチエントロピーアプローチは**ヒンテッドハンドオフ**と呼ばれる書き込み側の修復メカニズムです。ターゲットノードが書き込みを確認できない場合、コーディネーターまたはレプリカの1つが特定のヒントを保存し、ターゲットノードが復帰した時点でそのヒントが送信されます。

## マークルツリー

レプリカ間で正確にどの行が不一致しているかを見つけるには、データレコードをペアごとに交換して比較する必要があり、これは非現実的でコストがかかります。多くのデータベースは和解のコストを削減するために**マークルツリー**を採用しています。

マークルツリーはローカルデータのコンパクトなハッシュ表現を構成し、ハッシュのツリーを構築します：

- このハッシュツリーの最下層は、データレコードを保持するテーブル全体をスキャンすることで構築されます
- 上位のツリーレベルには、下位レベルのハッシュのハッシュが含まれます
- これによりハッシュ安定の階層的表現が構築され、不整合を迅速に検出できるようになります
- ハッシュを比較し、ハッシュツリーノードを再帰的にたどることで、不整合の範囲を絞り込むことができます

## ゴシッププロトコル

ゴシッププロトコルは、人間社会での噂の広がり方や疾病の拡散方法に基づいた確率的通信手順です：

- 拡散する必要のあるレコードを保持するプロセスは「感染した」と見なされます
- この情報を受け取ったプロセスは「感受性のある」状態になります
- ゴシップは同質な分散システムでの非同期メッセージ配信に使用できます
- これらのプロトコルは非常に堅牢で、分散システムに固有の信頼性の低さにもかかわらず、高い信頼性を実現するのに役立ちます

# 第13章: 分散トランザクション

## アトミックコミットメント

データベースでは、複数の操作をアトミックに実行する必要がよくあります。主な焦点は、操作を不可分かつ永続的に見せることです。このケースでは、それ以前に実行されたトランザクションの履歴が保存されます。

トランザクションのアトミック性は、その結果がすべて可視化されることを意味します。トランザクションが完了できない場合、その結果はロールバックされなければなりません。複数の操作をアトミックに見せるために、そのうちいくつかがリモートにある場合、アトミックコミットメントと呼ばれるアルゴリズムのクラスを使用する必要があります。

アトミックコミットメントは参加者間の不一致を許しません。参加者の一人でも反対票を投じれば、トランザクションはコミットされません。

## 二相コミット（2PC）

分散コミットメントのための最も単純なプロトコルである二相コミット（2PC）から始めましょう。2PCは通常、以下の構造で実装されます：

2PCは2つのフェーズで実行されます：

1. 第一フェーズでは、決定された値が配布され、投票が収集されます
2. 第二フェーズでは、ノードはスイッチを切り替えるだけで、第一フェーズの結果を可視化します

2PCはリーダーまたはコーディネーターの存在を前提としており、このコーディネーターは状態を保持し、投票を収集し、合意ラウンドの主要な参照点となります。残りのノードはコホートと呼ばれます。コホートは通常、トランザクションが実行される分離されたデータセットを操作するパーティションです。

### 2PCの障害シナリオ

いくつかの障害シナリオを考えてみましょう：

- コホートの一つが利用できない場合、コーディネーターはトランザクションを中止します。この要件は可用性に悪影響を及ぼします。
- 単一ノードの障害が進行を妨げる可能性があります。Spannerなどの一部のシステムでは、プロトコルの可用性を向上させるために、個々のノードではなくPaxosグループ上で2PCを実行します。

2PCの背後にある主なアイデアは、コホートが提案に肯定的に応答した後は、その決定を覆さないという約束です。そのため、コーディネーターだけがトランザクションを中止できます。

コホートの一つが提案を受け入れた後に障害が発生した場合、実際の投票結果について知る必要があります。コーディネーターが他のコホートの決定により、コミットを中止した可能性があるため、正しく値を提供できないからです。

コーディネーターがコミットまたは中止を進めることができない場合、クラスターは未決定状態のままになります。これは、コーディネーターが永続的に障害を起こした場合、コホートが最終決定について知ることができないことを意味します。このプロパティにより、2PCはブロッキングアトミックコミットメントアルゴリズムと言われます。

コーディネーターが回復しない場合、その代替は最終決定に先立って、与えられたトランザクションの投票を再度収集する必要があります。

多くのデータベース（MySQL、PostgreSQL、MongoDBなど）が2PCを使用しています。2PCはその単純さと低オーバーヘッドのため、分散トランザクションの実装によく使用されます。

## 三相コミット（3PC）

コーディネーターの障害に対して堅牢なアトミックコミットメントプロトコルを作成し、未決定状態を避けるために、三相コミットプロトコルには追加のステップと両側のタイムアウトがあり、コーディネー��ーの障害が発生した場合でも、システムの状態に応じてコホートがコミットまたは中止を進めることができます。

3PCは、提案フェーズの間にコーディネーターによって収集されたコホートの状態を伝達する準備フェーズをコミット/中止ステップの前に追加し、コーディネーターが障害を起こしても、プロトコルを継続できるようにします。

3PCのステップ：

1. **提案**：コーディネーターは提案された値を送信し、投票を収集します。
2. **準備**：コーディネーターは投票結果についてコホートに通知します。投票が可決され、すべてのコホートがコミットを決定した場合、コーディネーターはコミットの準備を指示する準備メッセージを送信します。そうでない場合は、中止メッセージが送信され、ラウンドは完了します。
3. **コミット**：コホートはコーディネーターによってトランザクションをコミットするよう通知されます。

## 競合の削減

トランザクションがロックを保持する総時間と競合を削減する他の方法もあります。一つの方法は、ロックを取得して実行を進める前に、レプリカに実行順序とトランザクション境界について合意させることです。

これを達成できれば、ノードの障害がトランザクションの中止を引き起こすべきではありません。なぜなら、ノードは同じトランザクションを並行して実行する他の参加者から状態を回復できるからです。

従来のデータベースシステムは、二相ロックや楽観的並行制御を使用してトランザクションを実行し、決定論的なトランザクション順序を持ちません。これは、順序を保存するためにノードを調整する必要があることを意味します。

決定論的なトランザクション順序は、実行フェーズ中の調整オーバーヘッドを削除し、すべてのレプリカが同じ入力を受け取るため、同等の出力も生成します。このアプローチは一般的にCalvinとして知られています。

## Calvin: 高速分散トランザクションプロトコル

Calvinを使用して分散トランザクションを実装する著名な例の一つはFaunaDBです。

Calvinは、分散トランザクション管理のための別のアプローチであるSpannerとよく対比されます。その実装には、最も著名なものとしてCockroachDBとYugaByteDBを含む、いくつかのオープンソースデータベースがあります。

Calvinがシーケンサー上のコンセンサスに到達することでグローバルなトランザクション実行順序を確立する一方、Spannerはパーティションごとのコンセンサスグループ上で二相コミットを使用します。

Spannerは複雑なセットアップを持っており、このプロジェクトの範囲では高レベルの詳細のみをカバーします。

## パーティショニング

多くのデータベースはパーティショニングを使用し、データを小さく管理しやすいセグメントに論理的に分割します。データをパーティショニングする最も単純な方法は、それを範囲に分割し、特定の範囲のみを管理するレプリカセットを許可することです。

クエリを実行する際、クライアントは読み取り/書き込み操作のために、ルーティングキーに基づいて正しいレプリカセットにリクエストをルーティングする必要があります。このパーティショニング方式は通常、シャーディングと呼ばれます。各レプリカセットはデータのサブセットの単一の真実源として機能します。

パーティションを最も効果的に使用するためには、負荷と値の分布を考慮してサイズを決定する必要があります。ノードがクラスターに追加または削除されると、データベースはバランスを維持するためにデータを再パーティショニングする必要があります。

一部のデータベースは自動シャーディングを実行し、最適なパーティショニングを決定する配置アルゴリズムを使用してデータを再配置します。これらのアルゴリズムは、読み取り/書き込み負荷と各シャード内のデータ量に関する情報を使用します。

## 一貫性のあるハッシュ

ルーティングキーからターゲットノードを見つけるために、一部のデータベースシステムはキーのハッシュを計算し、ハッシュ値からノードへのマッピングに使用します。レプリカ配置を決定するためにハッシュ関数を使用する利点の一つは、ハッシュ値が元の値と同じ方法でソートされないため、範囲のホットスポットを減らすのに役立つことです。

ハッシュ値をnode_iにマッピングする最も単純な方法は、ハッシュ値をクラスターのサイズで割った余りを取ることです。このアプローチの主な問題は、ノードが追加または削除されるたびに、ハッシュ値が元のものと異なることです。

この問題を軽減するために、一貫性のあるハッシュが使用されます。これは、ハッシュ関数によって返される値がリングにマッピングされ、最大の可能値の後に最小値にラップアラウンドするという異なるパーティショニングアプローチです。各ノードはリング上に独自の位置を持ち、値の範囲を担当します。

# 第14章: コンセンサス

## 分散システムにおけるコンセンサスアルゴリズム

コンセンサスアルゴリズムは、複数のプロセスが値について合意に達することを可能にします。FLP不可能性定理によると、完全に非同期なシステムでは有限時間内にコンセンサスを保証することは不可能です。メッセージ配信が保証されていても、あるプロセスが他のプロセスがクラッシュしたのか、単に処理が遅いのかを判断することは不可能です。

コンセンサスは以下の点で非常に有用です：

- イベントを特定の順序に配置する
- 参加者間の一貫性を確保する

コンセンサスを使用することで、プロセスが観察者にとって現在の値についての確実性を失うことなく、ある値から次の値へ移行するシステムが実現できます。

理論的な観点から、コンセンサスアルゴリズムには3つの特性があります：

1. 合意（Agreement）
2. 正当性（Validity）
3. 終了（Termination）

## ブロードキャストアルゴリズム

ブロードキャストアルゴリズムは、一連のプロセス間で情報を配信するために使用されます。単一の調整ノードが他のすべての参加者にデータを配布する必要があるデータベースレプリケーションでよく使用されますが、このプロセスを確実にすることは簡単ではありません。

### ベストエフォートブロードキャスト

メッセージをブロードキャストする最も単純な方法は、ベストエフォートブロードキャストです。この場合、送信者はすべてのターゲットへのメッセージ配信を確保する責任があります。送信者が失敗した場合、他の受動的なノードはメッセージを再ブロードキャストしようとしません。コーディネーターがクラッシュした場合、このタイプのブロードキャストは静かに失敗します。

### 信頼性のあるブロードキャスト

ブロードキャストが信頼性を持つためには、送信者が送信中にクラッシュしても、すべての正常なプロセスが同じメッセージを受信することを保証する必要があります。信頼性のあるブロードキャストを実装するには、障害検出器とフォールバックメカニズムを使用できます。

最も単純なフォールバックメカニズムは、メッセージを受信したすべてのプロセスが他のすべてのプロセスにそれを転送できるようにすることです。このアプローチの欠点の1つは、n²のメッセージを使用することであり、理想的ではありません。

### アトミックブロードキャスト

メッセージを順序通りに配信する必要がある場合は、信頼性のある配信と全体的な順序の両方を保証するアトミックブロードキャストを使用する必要があります。アトミックブロードキャストは以下を保証します：

- アトミック性：各メッセージはすべてのプロセスに配信されるか、どのプロセスにも配信されないかのどちらか
- 順序：メッセージはすべてのプロセスに同じ順序で配信される

## 仮想同期（Virtual Synchrony）

仮想同期は、ブロードキャストを使用したグループコミュニケーションのフレームワークです。アトミックブロードキャストが完全に順序付けられたメッセージの配信を支援する一方、仮想同期は動的なピアのグループに完全に順序付けられたメッセージを配信します。

仮想同期：

- プロセスをグループに編成する
- グループが存在する限り、メッセージはそのすべてのメンバーに同じ順序で配信される
- 参加者が参加、離脱、または失敗した場合、グループビューが変更される
- グループの変更はすべてのメンバーに通知される

## ZooKeeper Atomic Broadcast（ZAB）

アトミックブロードキャストの最も人気があり広く知られている実装の1つはZABで、ZooKeeperで使用されています。ZooKeeperは階層型分散キーバリューストアであり、ZABは一貫性を維持するために必要なイベントの全体的な順序とアトミックな配信を確保するために使用されます。

ZABのプロセスは次の2つの役割のいずれかを担うことができます：

- **リーダー**：アルゴリズムのステップを実行し、フォロワーにメッセージをブロードキャストし、単調に増加する一意の識別子でイベントの順序を確立する一時的な役割
- **フォロワー**：リーダーからメッセージを受信して処理する

リーダーの一意性を保証するために、プロトコルのタイムラインはエポックに分割され、各エポックは一意の番号で識別されます。どのエポックでも、リーダーは1つだけ存在できます。

プロトコルは3つのフェーズで動作します：

1. **発見（Discovery）**：見込みのあるリーダーは、他のすべてのプロセスが知っている最新のエポックについて学び、どのフォロワーの現在のエポックよりも大きい新しいエポックを提案します。フォロワーは最新のトランザクションに関する情報を含む提案に応答します。
2. **同期（Synchronization）**：このフェーズは遅れているフォロワーを回復させて最新の状態に戻すために使用されます。
3. **ブロードキャスト（Broadcast）**：フォロワーが同期すると、アクティブなメッセージングが開始されます。このフェーズでは、リーダーがクライアントからメッセージを受信し、順序を確立し、フォロワーにブロードキャストします。

ZABの利点：

- 効率性：ブロードキャストプロセスはメッセージの2ラウンドのみを必要とする
- リーダーの障害は、単一の最新プロセスから欠落しているメッセージをストリーミングすることで回復できる
- 長寿命のリーダーがいることは、イベント履歴を確立するための追加の複雑なラウンドを必要としないため、パフォーマンスにプラスの影響を与える

## Paxos

Paxosの参加者は次の3つの役割のいずれかを担うことができます：

- **提案者（Proposers）**：クライアントから値を受け取り、これらの値を受け入れるための提案を作成し、承認者から投票を集めようとする
- **承認者（Acceptors）**：提案者によって提案された値を受け入れるか拒否するかを投票する
- **学習者（Learners）**：レプリカの役割を担い、プロトコルの結果を保存する

障害耐性のために、アルゴリズムは複数の承認者を必要としますが、提案を受け入れるには承認者の投票のクォーラムのみが必要です。

Paxosアルゴリズムは一般的に2つのフェーズに分かれます：

1. 投票
2. レプリケーション

**クォーラム**は、一部の参加者が失敗しても、生存している参加者から投票を集めることができる限り、システムが進行できるようにするために使用されます。クォーラムは、操作を実行するために必要な最小投票数であり、通常は参加者の過半数で構成されます。

クォーラムの背後にある主なアイデアは、ネットワーク分断の場合に、プロトコルの正確性を確保する仲裁者として機能する参加者が少なくとも1つあることを確認することです。

障害シナリオの1つは、提案が第2フェーズで成功したが、すべての承認者に値をブロードキャストする前に失敗した場合です。この場合、新しい提案者が値を取り上げてコミットし、残りの参加者に配布することがあります。

## RAFT

Paxosは10年以上にわたってコンセンサスアルゴリズムの選択肢でしたが、理解と実装が難しいことで知られていました。2013年、Raftと呼ばれる新しいアルゴリズムが登場し、理解と実装が容易になるように設計されました。

Raftでは、参加者はステートマシンによって実行されるコマンドのシーケンスを含むログを保存します。リーダーがステートマシンの操作とレプリケーションを調整します。

Raftの各参加者は次の3つの役割のいずれかを担うことができます：

- **候補者（Candidate）**：リーダーになるために、ノードはまず候補者状態に移行し、ノードの過半数から投票を求める
- **リーダー（Leader）**：タームと呼ばれる期間のために選出された一時的なクラスターリーダー（単調に増加する数字で識別される）
- **フォロワー（Follower）**：ログエントリを永続化し、リーダーと候補者からのリクエストに応答する受動的な参加者（PaxosのAcceptorとLearnerに似ている）

複数のフォロワーが候補者になることを決定し、どの候補者も過半数の投票を集めることができない場合、Raftはランダム化されたタイマーを使用して分割投票の確率を減らします。

Raftアルゴリズムは以下の保証を提供します：

- 特定のタームでは、一度に1つのリーダーのみが選出される
- 同じタームで2つのリーダーが選出されることはない
- リーダーはログの内容を削除したり並べ替えたりせず、新しいメッセージのみを追加する
- コミットされたログエントリは保存される
- すべてのメッセージはメッセージとタームIDによって一意に識別される
- 現在のリーダーも後続のリーダーも同じ識別子を再利用することはできない

登場以来、Raftは分散システムの実装において非常に人気があります。
