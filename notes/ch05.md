# Chapter 5: Transaction Processing and Recovery

## Transaction Fundamentals

A transaction is an individual logical unit of work in a database management system, allowing you to represent multiple operations as a single step. A database transaction has to preserve atomicity, consistency, isolation, and durability. These properties are commonly referred to as ACID:

- **Atomicity** means that transaction steps are indivisible, which means that either all the steps associated with the transaction execute successfully or none do. In other words, transactions should not be applied partially. Each transaction can either commit or abort. Commit is the final operation. Abort rolls back transaction side effects.

- **Consistency** is an application-specific guarantee. A transaction should only bring the database from one valid state to another valid state, maintaining all database invariants, such as constraints, referential integrity, and others. Consistency is the most weakly defined property, possibly because it is the only property that is controlled by the user and not only by the database itself.

- **Isolation** means that multiple concurrently executing transactions should be able to run without interference, as if there were no other transactions executing at the same time.

- **Durability** means that once a transaction has been committed, all database state modifications have to be persisted on disk and be able to survive power outages, system failures and crashes.

## Implementing Transactions in Databases

Implementing transactions in a database storage structure requires several components to work together:

- The **transaction manager** coordinates and schedules transactions
- The **lock manager** gives access to resources and prevents concurrent accesses that would violate data integrity. Whenever a lock is requested, the lock manager checks if it is already held by any other transaction in shared or exclusive mode and grants access to it if the requested access level results in no contradiction.
- The **page cache** serves as an intermediary between persistent and volatile storage for state changes
- The **log manager** holds a history of operations

Most databases are built using a two-level memory hierarchy for persistent storage and volatile memory. To reduce the number of writes to persistent storage, pages are cached in memory. The page cache is sometimes referred to as the buffer pool.

Database systems are built on top of several hardware and software layers that can have their own stability and reliability issues. Database implementers have to consider these failure scenarios and make sure that the data that was promised to be written is in fact written.

## Write-Ahead Log (WAL)

A write-ahead log, WAL for short, also known as a commit log, is an append-only, disk-resident structure used for crash and transaction recovery. The page cache allows buffering changes to page contents in memory until the cached contents are flushed back to disk.

Many database systems use an append-only write-ahead log. The main functionality of WAL is to:

1. Allow the page cache to be buffered while ensuring durability is not affected
2. Persist operations on disk in a synchronized manner
3. Allow cached in-memory changes to be reconstructed from the operation log in case of a crash

The write-ahead log is append-only and its written content is immutable, so all writes to the log are sequential. Since the WAL is an immutable append-only data structure, readers can safely access its contents at the head while the writer continues appending data to the log trail.

## Concurrency Control

Transaction manager and lock manager work together to handle concurrency. This is a set of techniques that can be grouped into the following categories:

### Optimistic Concurrency Control

This allows transactions to execute concurrent read and write operations, and determines whether or not the result of the combined execution is serializable. In other words, transactions do not block each other, maintain histories of their operations, and abort if execution results in a conflict.

### Multi-Version Concurrency Control

This guarantees a consistent view of the database at some point in the past by allowing multiple versions of data.

### Pessimistic Concurrency Control

These are both lock-based and non-locking conservative methods, which differ in how they manage resources. Lock-based approaches require transactions to maintain locks on data. Non-locking approaches restrict which schedules can be executed.

## Transaction Schedules

Transactions consist of read and write operations executed against database state and business logic. A schedule is a list of operations required to execute a set of transactions from the database system perspective. A schedule is complete if it contains all operations from every transaction executed in it.

Correct schedules are logical equivalents to the original list of operations, but their parts can be executed in parallel or get reordered for optimization purposes.

A schedule is said to be serial when transactions in it are executed completely independently and without any interleaving. Every preceding transaction is fully executed before the next one starts. Serial execution is easy to reason about, but always executing transactions one after another would significantly impact the performance of the system.

We need to find a way to execute transaction operations concurrently while maintaining the correctness and simplicity of a serial schedule. We can achieve this with a serializable schedule. A schedule is serializable if it is equivalent to some complete serial schedule over the same set of transactions. In other words, it produces the same result as if we executed a set of transactions one after another in some order.

## Isolation Levels

Transaction or database systems allow different isolation levels. An isolation level specifies how and when parts of the transaction context should become visible to other transactions. Achieving isolation comes at the cost of preventing completed or temporary writes from propagation. This requires additional coordination and synchronization, which negatively impacts performance.

The SQL standard refers to and describes read anomalies that can occur during execution of concurrent transactions:

### Read Anomalies

- **Dirty read**: A situation in which a transaction can read uncommitted changes from other transactions.
- **Non-repeatable read** (or fuzzy read): A situation in which a transaction can read the same row twice and get different results. For example, this can happen if transaction T2 updates a row that T1 has read, and commits this change. If T1 requests the same row again before finishing its execution, the result will differ from the previous read.
- **Phantom read**: When a transaction queries the same set of rows twice and receives different results. It is similar to a non-repeatable read, but holds for range queries.

### Write Anomalies

- **Lost update**: Occurs when transactions T1 and T2 both attempt to update the same value. T1 and T2 read the value of V, T1 updates V and commits, and T2 updates V after that and commits as well. Since the transactions are not aware of each other's existence, if both of them are allowed to commit, the results of T1 will be overwritten by the results of T2 and updates from T1 will be lost.
- **Dirty write**: A situation in which one of the transactions takes an uncommitted value, modifies it, and saves it. In other words, when transaction results are based on a value that has never been committed.
- **Write skew**: Occurs when each individual transaction respects the required invariants, but their combination does not satisfy these invariants. For example, transactions T1 and T2 modify values of two accounts, A1 and A2. A1 starts with $100, and A2 starts with $150. The account value is allowed to be negative, as long as the sum of the two accounts is non-negative. T1 and T2 each attempt to withdraw $200 from A1 and A2 respectively. Since at the time these transactions started, A1+A2 equals $250 is available in total. Both transactions assume they are preserving the invariant and are allowed to commit. After the commit, A1 has -$100 and A2 has -$50, which clearly violates the requirement to keep the sum of the accounts positive.

## Isolation Levels in Detail

- **Read Uncommitted**: The lowest (weakest) isolation level. Under this isolation level, the transaction system allows one transaction to observe uncommitted changes of other concurrent transactions. In other words, dirty reads are allowed.

- **Read Committed**: We can avoid some of the anomalies by making sure that any read performed by a specific transaction can only read already committed changes. However, it is not guaranteed that if the transaction attempts to read the same data record once again at a later stage, it will see the same value. If there was a committed modification between two queries in the same transaction, we see different results. In other words, dirty reads are not permitted but phantom and non-repeatable reads are permitted.

- **Repeatable Read**: If we further disallow non-repeatable reads, we get a repeatable read isolation level.

- **Serializable**: The strongest isolation level. It guarantees that transaction outcomes will appear in some order, as if transactions were executed serially. Not allowing concurrent execution would have a substantial negative impact on performance.

## Concurrency Control Techniques

### Optimistic Concurrency Control

Optimistic concurrency control assumes that transaction conflicts occur rarely and instead of using locks and blocking transaction execution, we can validate transactions to prevent read/write conflicts with concurrently executing transactions and ensure serializability before committing. Transaction execution is split into three phases: read phase, validation phase, and write phase. Validation can be done by checking for conflicts.

### Multi-Version Concurrency Control (MVCC)

Multi-version concurrency control is a way to maintain multiple versions of data. This allows reads and writes to proceed with minimal coordination at the storage level since reads can continue accessing older values until the new ones are committed.

### Pessimistic Concurrency Control

Pessimistic concurrency control schemes are more conservative than optimistic ones:

- **Timestamp ordering**: This is lock-free. Each transaction has a timestamp. Transaction manager maintains max read timestamp and max write timestamp per value, describing read and write operations.

- **Two-Phase Locking (2PL)**: One of the most widespread lock-based techniques. It separates transaction execution into:
  - The growing phase during which all locks required by the transaction are acquired and no locks are released
  - The shrinking phase during which all locks acquired during the growing phase are released

## Deadlocks

A situation may occur when two transactions attempting to acquire locks end up waiting for each other to release the locks they hold. This situation is called a "deadlock".

The simplest way to handle deadlocks is to introduce timeouts and abort long-running transactions under the assumption that they might be in a deadlock. Another strategy, conservative 2PL, requires transactions to acquire all locks before they start execution. They can execute any of the operations and abort if they cannot. However, these approaches significantly limit system concurrency.

Database systems mostly use a transaction manager to detect or avoid deadlocks. Detecting deadlocks is generally done using a wait-for graph, which tracks relationships between the in-flight transactions.

# 第5章: トランザクション処理とリカバリー

## トランザクションの基礎

トランザクションはデータベース管理システムにおける個別の論理的な作業単位であり、複数の操作を単一のステップとして表現することができます。データベーストランザクションは原子性、一貫性、独立性、耐久性を保持する必要があります。これらの特性はACIDと総称されます：

- **原子性（Atomicity）**とは、トランザクションのステップが不可分であることを意味し、トランザクションに関連するすべてのステップが正常に実行されるか、まったく実行されないかのどちらかになります。つまり、トランザクションは部分的に適用されるべきではありません。各トランザクションはコミットするかアボートするかのどちらかです。コミットは最終操作です。アボートはトランザクションの副作用をロールバックします。

- **一貫性（Consistency）**はアプリケーション固有の保証です。トランザクションはデータベースを一つの有効な状態から別の有効な状態へと移行させるだけであり、制約、参照整合性などのすべてのデータベース不変条件を維持する必要があります。一貫性は最も弱く定義されたプロパティであり、おそらくそれはユーザーによって制御される唯一のプロパティであり、データベース自体だけによるものではないためです。

- **独立性（Isolation）**とは、同時に実行される複数のトランザクションが、あたかも同時に他のトランザクションが実行されていないかのように、干渉なく実行できることを意味します。

- **耐久性（Durability）**とは、トランザクションがコミットされると、すべてのデータベース状態の変更がディスクに永続化され、停電、システム障害、クラッシュなどに耐えられる必要があることを意味します。

## データベースでのトランザクションの実装

データベースのストレージ構造にトランザクションを実装するには、いくつかのコンポーネントが連携して動作する必要があります：

- **トランザクションマネージャ**はトランザクションを調整しスケジュールします
- **ロックマネージャ**はリソースへのアクセスを提供し、データの整合性を侵害する可能性のある同時アクセスを防止します。ロックが要求されるたびに、ロックマネージャは他のトランザクションによって共有モードまたは排他モードですでに保持されているかどうかを確認し、要求されたアクセスレベルが矛盾を引き起こさない場合にアクセスを許可します。
- **ページキャッシュ**は永続的ストレージと揮発性ストレージの間の仲介として機能し、状態変更を管理します
- **ログマネージャ**は操作の履歴を保持します

ほとんどのデータベースは、永続的ストレージと揮発性メモリのための2レベルのメモリ階層を使用して構築されています。永続的ストレージへの書き込み回数を減らすために、ページはメモリにキャッシュされます。ページキャッシュはバッファプールとも呼ばれることがあります。

データベースシステムは、独自の安定性と信頼性の問題を持つ可能性のあるいくつかのハードウェアおよびソフトウェア層の上に構築されています。データベース実装者はこれらの障害シナリオを考慮し、書き込まれることが約束されたデータが実際に書き込まれることを確認する必要があります。

## 先行書き込みログ（WAL）

先行書き込みログ（Write-Ahead Log、略してWAL）は、コミットログとも呼ばれ、クラッシュおよびトランザクションリカバリに使用される追記専用のディスク常駐構造です。ページキャッシュにより、キャッシュされた内容がディスクにフラッシュされるまで、ページの内容への変更をメモリにバッファリングすることができます。

多くのデータベースシステムは追記専用の先行書き込みログを使用しています。WALの主な機能は以下の通りです：

1. 耐久性に影響を与えることなく、ページキャッシュをバッファリングできるようにする
2. 操作を同期的にディスクに永続化する
3. クラッシュが発生した場合に、操作ログからキャッシュされたメモリ内の変更を再構築できるようにする

先行書き込みログは追記専用であり、書き込まれた内容は不変であるため、ログへのすべての書き込みは順次行われます。WALは不変の追記専用データ構造であるため、リーダーはログの先頭部分の内容に安全にアクセスできる一方、ライターはログの末尾にデータを追加し続けることができます。

## 並行制御

トランザクションマネージャとロックマネージャは協力して並行性を処理します。これは以下のカテゴリにグループ化できる一連の技術です：

### 楽観的並行制御

これにより、トランザクションは読み取りと書き込みの操作を同時に実行でき、結合された実行の結果が直列化可能かどうかを判断します。つまり、トランザクションは互いにブロックせず、操作の履歴を維持し、実行が競合を引き起こす場合はアボートします。

### マルチバージョン並行制御

これは、データの複数のバージョンを許可することで、過去のある時点でのデータベースの一貫したビューを保証します。

### 悲観的並行制御

これらはロックベースと非ロッキングの両方の保守的な方法であり、リソースの管理方法が異なります。ロックベースのアプローチでは、トランザクションはデータ上のロックを維持する必要があります。非ロッキングアプローチは、実行できるスケジュールを制限します。

## トランザクションスケジュール

トランザクションは、データベースの状態とビジネスロジックに対して実行される読み取りと書き込みの操作で構成されています。スケジュールは、データベースシステムの観点から一連のトランザクションを実行するために必要な操作のリストです。スケジュールは、その中で実行されるすべてのトランザクションからのすべての操作が含まれている場合、完全であるとされます。

正しいスケジュールは元の操作リストの論理的な等価物ですが、その部分は並列に実行されたり、最適化のために並べ替えられたりすることがあります。

スケジュールは、その中のトランザクションが完全に独立して実行され、インターリーブがない場合、直列であるとされます。次のトランザクションが開始される前に、先行するトランザクションが完全に実行されます。直列実行は理解しやすいですが、常にトランザクションを一つずつ実行することはシステムのパフォーマンスに大きな影響を与えるでしょう。

直列スケジュールの正確性と単純さを維持しながら、トランザクション操作を同時に実行する方法を見つける必要があります。これは直列化可能なスケジュールで達成できます。スケジュールは、同じトランザクションセット上の何らかの完全な直列スケジュールと等価である場合、直列化可能であるとされます。言い換えれば、あたかもトランザクションを何らかの順序で一つずつ実行したかのような結果を生成します。

## 分離レベル

トランザクションまたはデータベースシステムは異なる分離レベルを許可します。分離レベルは、トランザクションコンテキストの部分がいつどのように他のトランザクションに見えるようになるかを指定します。分離を達成するためには、完了した書き込みや一時的な書き込みが伝播するのを防ぐコストがかかります。これには追加の調整と同期が必要であり、パフォーマンスに悪影響を与えます。

SQL標準は、同時実行トランザクションの実行中に発生する可能性のある読み取り異常を参照し、説明しています：

### 読み取り異常

- **ダーティリード**：トランザクションが他のトランザクションからのコミットされていない変更を読み取ることができる状況。
- **反復不能読み取り**（またはファジーリード）：トランザクションが同じ行を2回読み取り、異なる結果を得ることができる状況。例えば、トランザクションT2がT1が読み取った行を更新し、この変更をコミットした場合に発生します。T1が実行を終了する前に同じ行を再度要求すると、結果は以前の読み取りと異なります。
- **ファントムリード**：トランザクションが同じ行セットを2回クエリして異なる結果を受け取る場合。これは反復不能読み取りに似て���ますが、範囲クエリに適用されます。

### 書き込み異常

- **失われた更新**：トランザクションT1とT2が両方とも同じ値を更新しようとする場合に発生します。T1とT2は値Vを読み取り、T1はVを更新してコミットし、T2はその後Vを更新してコミットします。トランザクションはお互いの存在を認識していないため、両方がコミットを許可された場合、T1の結果はT2の結果によって上書きされ、T1からの更新は失われます。
- **ダーティライト**：トランザクションの1つがコミットされていない値を取得し、それを修正して保存する状況。つまり、トランザクション結果がコミットされたことのない値に基づいている場合です。
- **ライトスキュー**：個々のトランザクションが必要な不変条件を尊重しているが、それらの組み合わせがこれらの不変条件を満たさない場合に発生します。例えば、トランザクションT1とT2が2つのアカウント、A1とA2の値を変更するとします。A1は$100から始まり、A2は$150から始まります。アカウント値は、2つのアカウントの合計が負でない限り、負になることが許可されています。T1とT2はそれぞれA1とA2から$200を引き出そうとします。これらのトランザクションが開始された時点では、A1+A2は合計$250が利用可能です。両方のトランザクションは不変条件を保持していると想定し、コミットが許可されます。コミット後、A1は-$100、A2は-$50となり、これはアカウントの合計を正に保つという要件に明らかに違反しています。

## 詳細な分離レベル

- **Read Uncommitted（未コミット読み取り）**：最低（最も弱い）分離レベル。このレベルでは、トランザクションシステムは1つのトランザクションが他の同時実行トランザクションのコミットされていない変更を観察することを許可します。つまり、ダーティリードが許可されています。

- **Read Committed（コミット済み読み取り）**：特定のトランザクションによって実行される読み取りが既にコミットされた変更のみを読み取ることができるようにすることで、いくつかの異常を回避できます。ただし、トランザクションが後の段階で同じデータレコードを再度読み取ろうとした場合、同じ値が表示されることは保証されていません。同じトランザクション内の2つのクエリの間にコミットされた変更があった場合、異なる結果が表示されます。つまり、ダーティリードは許可されませんが、ファントムリードと反復不能読み取りは許可されています。

- **Repeatable Read（反復可能読み取り）**：反復不能読み取りをさらに禁止すると、反復可能読み取り分離レベルが得られます。

- **Serializable（直列化可能）**：最強の分離レベル。トランザクションの結果があたかもトランザクションが直列に実行されたかのように、ある順序で表示されることを保証します。同時実行を許可しないことは、パフォーマンスに大きな悪影響を与えるでしょう。

## 並行制御技術

### 楽観的並行制御

楽観的並行制御は、トランザクションの競合が稀に発生すると想定し、ロックを使用してトランザクションの実行をブロックする代わりに、同時実行トランザクションとの読み取り/書き込みの競合を防ぎ、コミット前に直列化可能性を確保するためにトランザクションを検証できます。トランザクション実行は、読み取りフェーズ、検証フェーズ、書き込みフェーズの3つのフェーズに分かれています。検証は競合をチェックすることによって行うことができます。

### マルチバージョン並行制御（MVCC）

マルチバージョン並行制御はデータの複数のバージョンを維持する方法です。これにより、読み取りは新しい値がコミットされるまで古い値にアクセスし続けることができるため、ストレージレベルでの調整を最小限に抑えて読み取りと書き込みを進めることができます。

### 悲観的並行制御

悲観的並行制御スキームは楽観的なものよりも保守的です：

- **タイムスタンプオーダリング**：これはロックフリーです。各トランザクションにはタイムスタンプがあります。トランザクションマネージャは、読み取りと書き込みの操作を記述する値ごとに最大読み取りタイムスタンプと最大書き込みタイムスタンプを維持します。

- **二相ロック（2PL）**：最も広く使用されているロックベースの技術の1つです。トランザクションの実行を以下のように分けます：
  - 成長フェーズ：トランザクションに必要なすべてのロックが取得され、ロックは解放されません
  - 縮小フェーズ：成長フェーズ中に取得されたすべてのロックが解放されます

## デッドロック

ロックを取得しようとする2つのトランザクションが、互いが保持しているロックを解放するのを待っている状況が発生することがあります。この状況は「デッドロック」と呼ばれます。

デッドロックを処理する最も単純な方法は、タイムアウトを導入し、デッドロックに陥っている可能性があるという前提で長時間実行されているトランザクションをアボートすることです。別の戦略である保守的2PLでは、トランザクションが実行を開始する前にすべてのロックを取得する必要があります。操作を実行し、できない場合はアボートできます。ただし、これらのアプローチはシステムの同時実行性を大幅に制限します。

データベースシステムは主にトランザクションマネージャを使用してデッドロックを検出または回避します。デッドロックの検出は通常、実行中のトランザクション間の関係を追跡する待ちグラフを使用して行われます。
